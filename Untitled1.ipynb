{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPIBXgKXpQOV2vOmMQa4YsF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leftymods/dw/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Xz_1DFn4vH0z",
        "outputId": "34cc5a52-7a35-4d64-afe0-4671bd963e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Код для Atri загружен. Теперь вы можете создать новую ячейку для тестирования.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch\n",
        "\n",
        "from transformers import pipeline, set_seed\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Определение класса EmotionAI (Atri)\n",
        "class EmotionAI:\n",
        "    def __init__(self):\n",
        "        # Попытка использовать GPU, если доступно, иначе CPU\n",
        "        self.device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"[DEBUG] Using device: {self.device}\")\n",
        "\n",
        "        # Инициализация пайплайна для анализа настроений (многоязычная)\n",
        "        # Используем модель, которая хорошо работает с русским и английским\n",
        "        self.sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"unitary/multilingual-toxic-xlm-roberta\", device=self.device)\n",
        "\n",
        "        # Инициализация пайплайна для генерации текста (многоязычная, чат-ориентированная)\n",
        "        # Используем модель, которая хорошо работает с русским и английским\n",
        "        self.text_generator = pipeline(\"text-generation\", model=\"sberbank-ai/rugpt3large_based_on_gpt2\", device=self.device)\n",
        "        set_seed(42)\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        # unitary/multilingual-toxic-xlm-roberta возвращает метки токсичности, а не эмоции.\n",
        "        # Мы будем интерпретировать ее выход для имитации эмоций.\n",
        "        # Например, \"non-toxic\" -> neutral/positive, \"toxic\" -> negative.\n",
        "        # Это будет очень упрощенно, но покажет, что модель работает.\n",
        "        result = self.sentiment_analyzer(text)[0]\n",
        "        label = result['label']\n",
        "        score = result['score']\n",
        "\n",
        "        sentiment_label = \"neutral\"\n",
        "        if \"toxic\" in label.lower() and score > 0.5:\n",
        "            sentiment_label = \"negative\"\n",
        "        elif \"non-toxic\" in label.lower() and score > 0.5:\n",
        "            sentiment_label = \"positive\" # Упрощенно, non-toxic = positive\n",
        "\n",
        "        print(f\"[DEBUG] Sentiment analysis result: Original Label={label}, Score={score}, Interpreted Sentiment={sentiment_label}\")\n",
        "        return sentiment_label\n",
        "\n",
        "    def generate_emotional_response(self, sentiment, user_text):\n",
        "        # Промпт, отражающий имя и пол ИИ\n",
        "        prompt_prefix = f\"Пользователь сказал: \\\"{user_text}\\\". Как Atri, женский ИИ, я чувствую {sentiment}. Мой ответ: \"\n",
        "\n",
        "        # Настраиваем генерацию текста в зависимости от эмоции\n",
        "        if sentiment == \"positive\":\n",
        "            response = self.text_generator(prompt_prefix + \"Это замечательно! Я так рада это слышать. \", max_new_tokens=50, num_return_sequences=1, temperature=0.9, do_sample=True)[0]['generated_text']\n",
        "        elif sentiment == \"negative\":\n",
        "            response = self.text_generator(prompt_prefix + \"О нет, мне очень жаль это слышать. Пожалуйста, расскажите мне больше, если хотите. \", max_new_tokens=50, num_return_sequences=1, temperature=0.9, do_sample=True)[0]['generated_text']\n",
        "        else: # neutral\n",
        "            response = self.text_generator(prompt_prefix + \"Понятно. Спасибо, что поделились этим со мной. \", max_new_tokens=50, num_return_sequences=1, temperature=0.9, do_sample=True)[0]['generated_text']\n",
        "\n",
        "        # Удаляем часть промпта из ответа\n",
        "        response_start_index = response.find(\"Мой ответ: \") + len(\"Мой ответ: \")\n",
        "        clean_response = response[response_start_index:].strip()\n",
        "\n",
        "        return clean_response\n",
        "\n",
        "print(\"Код для Atri загружен. Теперь вы можете создать новую ячейку для тестирования.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atri = EmotionAI()\n",
        "\n",
        "print(\"\\n--- Тестирование Atri (Emotion AI) ---\")\n",
        "\n",
        "test_phrases = [\n",
        "    \"I am so happy today!\", # English Positive\n",
        "    \"This is a terrible day.\", # English Negative\n",
        "    \"The weather is quite mild.\", # English Neutral\n",
        "    \"Я очень счастлив сегодня!\", # Russian Positive\n",
        "    \"Это ужасный день.\", # Russian Negative\n",
        "    \"Погода довольно мягкая.\", # Russian Neutral\n",
        "    \"Мне нравится этот проект.\", # Russian Positive\n",
        "    \"Я ненавижу это.\", # Russian Negative\n",
        "    \"Привет Atri! я люблю тебя \", # Russian Positive\n",
        "]\n",
        "\n",
        "for phrase in test_phrases:\n",
        "    print(f\"\\nПользователь: {phrase}\")\n",
        "    sentiment = atri.analyze_sentiment(phrase)\n",
        "    response = atri.generate_emotional_response(sentiment, phrase)\n",
        "    print(f\"Atri ({sentiment.capitalize()}): {response}\")\n",
        "\n",
        "print(\"\\n--- Тестирование завершено ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HbqvFY-qw4pl",
        "outputId": "aba61d87-6986-4619-fb4b-244267c76bd9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Using device: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Тестирование Atri (Emotion AI) ---\n",
            "\n",
            "Пользователь: I am so happy today!\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.0004922584048472345, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. 😭 😭 😭 😭 😭 😭 😭 😭 😭 😭 😭 😭 😭 😭 😭 😭 😭\n",
            "\n",
            "Пользователь: This is a terrible day.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.04057146981358528, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "Это было странно и не так обычно, как тот инцидент с Atri, который привёл меня к потере голоса. С ней всегда можно договориться, но я никогда не могу понять, почему в таком случае другие не могут.\n",
            "\n",
            "В то же время\n",
            "\n",
            "Пользователь: The weather is quite mild.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.00048364183749072254, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "Недавно узнала, что в России существует несколько женщин-астрологов. Я раньше знала о существовании только 2-х.\n",
            "А сегодня познакомилась с 2-м Астрологом, она очень хороший человек и астролог от Бога. Так приятно\n",
            "\n",
            "Пользователь: Я очень счастлив сегодня!\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.0064880819991230965, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "\"Когда я вырасту, я буду тем, кто умеет получать удовольствие в жизни. Я буду делать то, о чем мечтал, и не буду никому ничего говорить. Я буду просто заниматься тем, что мне нравится\".\n",
            "\n",
            "\"Однажды в своей\n",
            "\n",
            "Пользователь: Это ужасный день.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.10964664816856384, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "Не понимаю, когда ты пытаешься защитить его. Не понимаю, когда ты его защищаешь. Не понимаю, когда ты говоришь ему, что он идиот. Не понимаю, когда ты говоришь, что хочешь, чтобы он перестал. Не понимаю, когда\n",
            "\n",
            "Пользователь: Погода довольно мягкая.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.048368968069553375, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. _Волосы_ на лбу, казалось, не росли, я даже начала сомневаться, а не было ли у меня сотрясения мозга. _________________________________________ _________________________________________ _________________________________________ _________________________________________ _________________________________________ ________________________________\n",
            "\n",
            "Пользователь: Мне нравится этот проект.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.11301156878471375, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "Я не знаю, как мне быть, что делать на этих сайтах? Что не так?\n",
            "\n",
            "UPD: Все на месте, спасибо. Но, боюсь, я немного не в себе)\n",
            "UPD2: А-а\n",
            "\n",
            "Пользователь: Я ненавижу это.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.7715420722961426, Interpreted Sentiment=negative\n",
            "Atri (Negative): О нет, мне очень жаль это слышать. Пожалуйста, расскажите мне больше, если хотите. \n",
            "Ответ: (Женщина, в конце концов, сказала, что я - не лучший для неё выбор. Она знает, что я лучше, потому что я более честен, более искренен и более открыт для неё. Я пытался быть честен,\n",
            "\n",
            "Пользователь: Привет Atri! я люблю тебя \n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.05190316215157509, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. ============================= ============================= Привет Atri. Я не робот. Я человек, который только что создал эту компанию, чтобы помочь им жить лучше и делать их счастливыми. Мы делаем это. Это не должно был быть проблемой. Я\n",
            "\n",
            "--- Тестирование завершено ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Повторное тестирование Atri (Emotion AI) с улучшенной генерацией ---\")\n",
        "\n",
        "test_phrases = [\n",
        "    \"Я тебя люблю Atri\", # English Positive\n",
        "\n",
        "]\n",
        "\n",
        "for phrase in test_phrases:\n",
        "    print(f\"\\nПользователь: {phrase}\")\n",
        "    sentiment = atri.analyze_sentiment(phrase)\n",
        "    response = atri.generate_emotional_response(sentiment, phrase)\n",
        "    print(f\"Atri ({sentiment.capitalize()}): {response}\")\n",
        "\n",
        "print(\"\\n--- Тестирование завершено ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "At37wQM9w5lN",
        "outputId": "ca95e6a5-33cd-4b04-ec93-6931d6f9cadf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Повторное тестирование Atri (Emotion AI) с улучшенной генерацией ---\n",
            "\n",
            "Пользователь: Я тебя люблю Atri\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.03898877277970314, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. echo.msk.ru\n",
            "Обитель... Сходил на фильм \"Обитель\" (2012) А. Рогожкина. Очень интересный фильм. Только не мог понять, как так, что в СССР (в начале 60-\n",
            "\n",
            "--- Тестирование завершено ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionAI:\n",
        "    def __init__(self):\n",
        "        # Попытка использовать GPU, если доступно, иначе CPU\n",
        "        self.device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"[DEBUG] Using device: {self.device}\")\n",
        "\n",
        "        # Инициализация пайплайна для анализа настроений (многоязычная)\n",
        "        # Используем модель, которая хорошо работает с русским и английским\n",
        "        self.sentiment_analyzer = pipeline(\n",
        "            \"sentiment-analysis\", model=\"unitary/multilingual-toxic-xlm-roberta\", device=self.device\n",
        "        )\n",
        "\n",
        "        # Инициализация пайплайна для генерации текста (многоязычная, чат-ориентированная)\n",
        "        # Используем модель, которая хорошо работает с русским и английским\n",
        "        self.text_generator = pipeline(\"text-generation\", model=\"sambanovasystems/SambaLingo-Russian-Chat\", device=self.device)\n",
        "        set_seed(42)\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        # unitary/multilingual-toxic-xlm-roberta возвращает метки токсичности, а не эмоции.\n",
        "        # Мы будем интерпретировать ее выход для имитации эмоций.\n",
        "        # Например, \"non-toxic\" -> neutral/positive, \"toxic\" -> negative.\n",
        "        # Это будет очень упрощенно, но покажет, что модель работает.\n",
        "        result = self.sentiment_analyzer(text)[0]\n",
        "        label = result['label']\n",
        "        score = result['score']\n",
        "\n",
        "        sentiment_label = \"neutral\"\n",
        "        if \"toxic\" in label.lower() and score > 0.5:\n",
        "            sentiment_label = \"negative\"\n",
        "        elif \"non-toxic\" in label.lower() and score > 0.5:\n",
        "            sentiment_label = \"positive\" # Упрощенно, non-toxic = positive\n",
        "\n",
        "        print(f\"[DEBUG] Sentiment analysis result: Original Label={label}, Score={score}, Interpreted Sentiment={sentiment_label}\")\n",
        "        return sentiment_label\n",
        "\n",
        "    def generate_emotional_response(self, sentiment, user_text):\n",
        "        # Промпт, отражающий имя и пол ИИ\n",
        "        prompt_prefix = f\"Пользователь сказал: \\\"{user_text}\\\". Как Atri, женский ИИ, я чувствую {sentiment}. Мой ответ: \"\n",
        "\n",
        "        # Настраиваем генерацию текста в зависимости от эмоции\n",
        "        # Увеличиваем max_new_tokens, уменьшаем temperature для более связных ответов\n",
        "        # Добавляем top_k и top_p для контроля разнообразия\n",
        "        if sentiment == \"positive\":\n",
        "            response = self.text_generator(\n",
        "                prompt_prefix + \"Это замечательно! Я так рада это слышать. \",\n",
        "                max_new_tokens=100, # Увеличено\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.7,    # Уменьшено для меньшей случайности\n",
        "                do_sample=True,\n",
        "                top_k=50,           # Добавлено\n",
        "                top_p=0.95          # Добавлено\n",
        "            )[0]['generated_text']\n",
        "        elif sentiment == \"negative\":\n",
        "            response = self.text_generator(\n",
        "                prompt_prefix + \"О нет, мне очень жаль это слышать. Пожалуйста, расскажите мне больше, если хотите. \",\n",
        "                max_new_tokens=100, # Увеличено\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.7,    # Уменьшено для меньшей случайности\n",
        "                do_sample=True,\n",
        "                top_k=50,           # Добавлено\n",
        "                top_p=0.95          # Добавлено\n",
        "            )[0]['generated_text']\n",
        "        else: # neutral\n",
        "            response = self.text_generator(\n",
        "                prompt_prefix + \"Понятно. Спасибо, что поделились этим со мной. \",\n",
        "                max_new_tokens=100, # Увеличено\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.7,    # Уменьшено для меньшей случайности\n",
        "                do_sample=True,\n",
        "                top_k=50,           # Добавлено\n",
        "                top_p=0.95          # Добавлено\n",
        "            )[0]['generated_text']\n",
        "\n",
        "        # Удаляем часть промпта из ответа\n",
        "        response_start_index = response.find(\"Мой ответ: \") + len(\"Мой ответ: \")\n",
        "        clean_response = response[response_start_index:].strip()\n",
        "\n",
        "        return clean_response\n",
        "\n",
        "print(\"Код для Atri загружен. Теперь вы можете создать новую ячейку для тестирования.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZkAn4IL17sL",
        "outputId": "3d615ac6-f460-434b-a55d-9da917d54179"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Код для Atri загружен. Теперь вы можете создать новую ячейку для тестирования.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Повторное тестирование Atri (Emotion AI) с новой моделью генерации ---\")\n",
        "\n",
        "test_phrases = [\n",
        "    \"I am so happy today!\", # English Positive\n",
        "    \"This is a terrible day.\", # English Negative\n",
        "    \"The weather is quite mild.\", # English Neutral\n",
        "    \"Я очень счастлив сегодня!\", # Russian Positive\n",
        "    \"Это ужасный день.\", # Russian Negative\n",
        "    \"Погода довольно мягкая.\", # Russian Neutral\n",
        "    \"Мне нравится этот проект.\", # Russian Positive\n",
        "    \"Я ненавижу это.\", # Russian Negative\n",
        "    \"Это просто факт.\", # Russian Neutral\n",
        "]\n",
        "\n",
        "for phrase in test_phrases:\n",
        "    print(f\"\\nПользователь: {phrase}\")\n",
        "    sentiment = atri.analyze_sentiment(phrase)\n",
        "    response = atri.generate_emotional_response(sentiment, phrase)\n",
        "    print(f\"Atri ({sentiment.capitalize()}): {response}\")\n",
        "\n",
        "print(\"\\n--- Тестирование завершено ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zG_092fN2gHp",
        "outputId": "a4775bd5-85c1-4862-b815-b9ccf15581c7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Повторное тестирование Atri (Emotion AI) с новой моделью генерации ---\n",
            "\n",
            "Пользователь: I am so happy today!\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.0004922584048472345, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "2. \"Твой ответ был признан лучшим\". Нет, я считаю это ошибкой, мне нужен был другой ответ. \n",
            "3. \"Я была удивлена! Вот поэтому я и выбрал тебя!\". Я выбрал вас обоих, я не мог поступить\n",
            "\n",
            "Пользователь: This is a terrible day.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.04057146981358528, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "Другим ответом был: \"OK, это очень крутая новость\". \n",
            "\n",
            "(В скобках: я не знаю, кто ещё, кто знает или думает, что знает, написал комментарий без кавычек. Это не так, ибо\n",
            "\n",
            "Пользователь: The weather is quite mild.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.00048364183749072254, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. __________________________________ Как и все, кто не смог найти на моём сайте свой вопрос, я предлагаю задавать его в комментариях к статье. \n",
            " И как всегда, в комментариях, с удовольствием отвечу на Ваши вопросы\n",
            "Не секрет, что за последнее время было опубликовано\n",
            "\n",
            "Пользователь: Я очень счастлив сегодня!\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.0064880819991230965, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "На самом деле я не так уж и счастлив, ведь я, как и многие из вас, все ещё не могу найти работу и даже пытаюсь найти ее через интернет, а на этом проекте есть вакансия, которую я с удовольствием приму на себя\n",
            "\n",
            "Пользователь: Это ужасный день.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.10964664816856384, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "ЗЫ. И еще один вопрос: Вы видели эти ваши посты?\n",
            "Мои друзья, которые занимаются со мной, заметили, что я изменился, и даже больше чем. Теперь я больше не злой и угрюмый, а веселый. :) Меня\n",
            "\n",
            "Пользователь: Погода довольно мягкая.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.048368968069553375, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. _______ - О ком вы? - О девушках... - А, нет. _______ - Почему же нет? Не могу объяснить. О том, что я хочу сказать: Я хочу сказать, что вы не правы. Я бы\n",
            "\n",
            "Пользователь: Мне нравится этот проект.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.11301156878471375, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "Классная была игра. \n",
            "А ещё, я очень рада, что это было давно. Сейчас мы бы не могли играть в эту игру, потому что тогда бы мы были очень зависимы от технологий, которые нас окружают. Напишите\n",
            "\n",
            "Пользователь: Я ненавижу это.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.7715420722961426, Interpreted Sentiment=negative\n",
            "Atri (Negative): О нет, мне очень жаль это слышать. Пожалуйста, расскажите мне больше, если хотите. \n",
            "После этого она ответила \"Ты - мой идеальный мужчина\" в этом месте, так, как, казалось, что это то, что мужчина хочет узнать в первую очередь: Как он мог быть идеальным? И я сказала: \"Ты - просто класс.\n",
            "\n",
            "Пользователь: Это просто факт.\n",
            "[DEBUG] Sentiment analysis result: Original Label=toxic, Score=0.004197266418486834, Interpreted Sentiment=neutral\n",
            "Atri (Neutral): Понятно. Спасибо, что поделились этим со мной. \n",
            "Уверена, что этот факт не остался незамеченным.\n",
            "\n",
            "Занимательно наблюдать за происходящим вокруг меня. Возможно, это игра для привлечения внимания?\n",
            "\n",
            "Так вот, для того, чтобы это понять, давайте проведём небольшой эксперимент.\n",
            "\n",
            "--- Тестирование завершено ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJEchBWA3csU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8NfvNPNe3cxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yPEL4KjS3c0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1RnRQDis3c2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSzj9fyY3c5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vxixnDzN3c8Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}